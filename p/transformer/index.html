<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="对Tansformer的简单理解"><title>Tansformer学习笔记</title>
<link rel=canonical href=https://lhy0424.top/p/transformer/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Tansformer学习笔记"><meta property='og:description' content="对Tansformer的简单理解"><meta property='og:url' content='https://lhy0424.top/p/transformer/'><meta property='og:site_name' content="Az's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Deep learning'><meta property='article:tag' content='Transformer'><meta property='article:published_time' content='2025-03-10T15:32:00+00:00'><meta property='article:modified_time' content='2025-03-10T15:32:00+00:00'><meta property='og:image' content='https://lhy0424.top/p/transformer/transformers_2b9aba81a7.jpg'><meta name=twitter:title content="Tansformer学习笔记"><meta name=twitter:description content="对Tansformer的简单理解"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://lhy0424.top/p/transformer/transformers_2b9aba81a7.jpg'><link rel="shortcut icon" href=/img/az.jpg></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/az_hu_2167c1e5a8cad978.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Az's Blog</a></h1><h2 class=site-description>Stay hungry, Stay foolish.</h2></div></header><ol class=menu-social><li><a href=https://github.com/Accepted0424 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com target=_blank title=Twitter rel=me><svg class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#a-high-level-look>A High-Level Look</a></li><li><a href=#token-embedding-词嵌入>Token Embedding 词嵌入</a></li><li><a href=#positional-encoding>Positional encoding</a></li><li><a href=#encoder>Encoder</a><ol><li><a href=#self-attention-自注意力机制>Self-Attention 自注意力机制</a><ol><li></li><li><a href=#multi-head-attention-多头注意力机制>Multi-head attention 多头注意力机制</a></li></ol></li><li><a href=#inside-the-multilayer-perception-多层感知器>Inside the Multilayer Perception 多层感知器</a><ol><li><a href=#linear-up-projection>Linear (up projection)</a></li><li><a href=#relu线性整流函数>ReLU线性整流函数</a></li><li><a href=#linear-down-projection>Linear (down projection)</a></li></ol></li><li><a href=#residuals-残差>Residuals 残差</a></li></ol></li><li><a href=#decoder>Decoder</a></li><li><a href=#linear-layer>Linear Layer</a></li><li><a href=#softmax-with-temperature>softmax with temperature</a></li><li><a href=#参考资料>参考资料</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/transformer/><img src=/p/transformer/transformers_2b9aba81a7_hu_71935be9ef28b374.jpg srcset="/p/transformer/transformers_2b9aba81a7_hu_71935be9ef28b374.jpg 800w, /p/transformer/transformers_2b9aba81a7_hu_8f3b2f01b9283b42.jpg 1600w" width=800 height=267 loading=lazy alt="Featured image of post Tansformer学习笔记"></a></div><div class=article-details><header class=article-category><a href=/categories/transformer/>Transformer</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/transformer/>Tansformer学习笔记</a></h2><h3 class=article-subtitle>对Tansformer的简单理解</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Mar 10, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 6 分钟</time></div></footer></div></header><section class=article-content><h1 id=transformer>Transformer</h1><p>Transformer 最早在2017年的<a class=link href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.03762" target=_blank rel=noopener>《Attention Is All You Need》</a>论文中提出，通过引入 <strong>自注意力（Self-Attention）+ 位置编码（Positional Encoding）+ 多头注意力（Multi-Head Attention）+ 前馈网络（Feed-Forward Network）</strong>，解决了传统 Seq2Seq 模型在处理<strong>可变长序列</strong>时的长距离依赖、计算效率等关键问题。</p><blockquote><p><strong>seq2seq</strong>，序列到序列，输入为一段序列，输出也是一段序列，如翻译任务。</p><p><strong>处理可变长序列</strong>，指的是在自然语言处理（NLP）等任务中，模型需要能够应对<strong>不同长度</strong>的输入或输出序列，而不是固定长度的数据。</p></blockquote><p>with transformer you can</p><ul><li>voice-to-text</li><li>text-to-voice</li><li>text-to-image&mldr;</li></ul><p>《Attention is All You Need》专注于把一种语言翻译成另一种，这也是Transformer最初的设计目的，而后来被广泛应用于各种自然语言处理（NLP）任务，比如ChatGPT、DeepSeek等大模型，本文主要介绍最基础的transformer结构。</p><h2 id=a-high-level-look>A High-Level Look</h2>$$
Transfomer(我是一个学生) = I\space am\space a\space studuent
$$<p><img src=/p/transformer/100338.png width=2464 height=1372 srcset="/p/transformer/100338_hu_1ca66c0856641636.png 480w, /p/transformer/100338_hu_f6af1cf1143230d9.png 1024w" loading=lazy class=gallery-image data-flex-grow=179 data-flex-basis=431px></p><p><img src=https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png loading=lazy alt=img></p><p><img src=/p/transformer/221542.png width=530 height=696 srcset="/p/transformer/221542_hu_420c5707aadfcde8.png 480w, /p/transformer/221542_hu_e0f8e7941159190f.png 1024w" loading=lazy class=gallery-image data-flex-grow=76 data-flex-basis=182px></p><h2 id=token-embedding-词嵌入>Token Embedding 词嵌入</h2><blockquote><p><em><strong>Can you can a can like a canner can a can.</strong></em></p></blockquote><ul><li>token? 单词片段或标点符号</li><li>将每个token转化为对应的高维向量，构成Embedding matrix<ul><li>Embedding matrix随机初始化，并通过数据进行学习</li><li>GPT-3中每个token的向量有12288个维度</li><li>向量的方向代表语义，语义相似的token有着相似的方向</li><li>两个词的差异也会体现在向量之差，例如man和woman的向量之差与uncle和aunt的向量之差相似，也可以理解为$\vec{uncle}+(\vec{woman}-\vec{man}) = \vec{aunt}$</li></ul></li><li>得到的词向量无上下文语义，但是其性质决定其可以用于分析上下文<ul><li>Attention的目标就是让单个token通过上下文获得更丰富的语义。（比如判断出每个can的含义）</li><li>上下文长度指的即是模型每次能处理的向量数目（预测下一个token时结合的文本量）</li></ul></li><li>Unembedding matrix 解嵌入矩阵，可以将一个向量解析为对应的单词</li></ul><p><img src=/p/transformer/100732.png width=2499 height=1085 srcset="/p/transformer/100732_hu_9ddc44a6431ecfa0.png 480w, /p/transformer/100732_hu_acbdc36ac31700b5.png 1024w" loading=lazy class=gallery-image data-flex-grow=230 data-flex-basis=552px></p><p><img src=/p/transformer/102903.png width=2555 height=791 srcset="/p/transformer/102903_hu_838a9c3c8ff3b961.png 480w, /p/transformer/102903_hu_bfa74c1c85bd8f7c.png 1024w" loading=lazy class=gallery-image data-flex-grow=323 data-flex-basis=775px></p><h2 id=positional-encoding>Positional encoding</h2><p>引入额外的位置编码刻画数据在时序上的特征</p>$$
PE_{pos,2i}=sin(pos/10000^{2i/d_{model}})\\
PE_{pos,2i+1}=cos(pos/10000^{2i/d_{model}})
$$<p><img src=https://jalammar.github.io/images/t/transformer_positional_encoding_vectors.png loading=lazy alt=transformer_positional_encoding_vectors></p><h2 id=encoder>Encoder</h2><ul><li>self-attention自注意力机制</li><li>Feed Forward Neural Network 前馈神经网络</li></ul><p><img src=https://jalammar.github.io/images/t/encoder_with_tensors.png loading=lazy alt=encoder_with_tensors></p><h3 id=self-attention-自注意力机制>Self-Attention 自注意力机制</h3><blockquote><p><em><strong>“ Can you can a can like a canner can a can. ”</strong></em></p></blockquote><ul><li>can 代指的是什么？需要联系上下文</li></ul><h5 id=qkv>Q、K、V</h5><p>**如何理解矩阵形式的Q、K、V：**在map/dict查询时我们可以根据key查询数据，如果query=key，那么取出key对应的数据。但是对于矩阵形式的Q、K、V，这样并不可行，只能变得soft一些，计算query和key的关系之后再对value加权求和。（softmax也是类似的思想）</p><ul><li><p>$Query\space vector = \vec{E} \times W_Q$</p></li><li><p>$ Key\space vector=\vec{E}\times W_K$</p></li><li><p>$Value\space vector = \vec{E}\times W_V$</p><ul><li>Value反映了如果要改变目标词的语义，需要对目标词的embedding加上一个什么样的向量</li></ul></li><li><p>$W_K\space W_K\space W_V$均通过训练获得</p></li></ul><p><img src=https://jalammar.github.io/images/t/transformer_self_attention_vectors.png loading=lazy alt=transformer_self_attention_vectors></p>$$
Softmax(\frac{q_i\cdot k_j}{\sqrt{d_k}})\\ d_k\space is\space the \space dimension\space of\space the\space key\space vector
$$<p>这个公式表示在j位置的token在i位置的表达量，显然i位置本身的token在i位置表达量最大。</p><ul><li>query点乘key得到一个较大的正数，即称key代表的embedding注意到了query代表的embedding</li><li>如果是一个较小值或负值，则代表两个词互不相关</li></ul><p><img src=https://jalammar.github.io/images/t/self-attention_softmax.png loading=lazy alt=self-attention_softmax></p>$$
z_i = \sum_{j=1}^{n} softmax(\frac{q_i\cdot k_j}{\sqrt{d_k}}) \times v_j \\or\\
Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{d_k}})V
$$<p>之后我们用softmax score乘每个位置上的value向量再求和，即可得到该位置上的self-attention层的输出向量$z_1$，$z_1$之后会传入feed-forward neural network。</p><p><img src=https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png loading=lazy alt=self-attention-matrix-calculation-2></p><h4 id=multi-head-attention-多头注意力机制>Multi-head attention 多头注意力机制</h4><p>模型在对当前位置的信息进行编码时，会过度的将注意力集中于自身的位置</p><blockquote><p>Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions.</p></blockquote><ul><li><p>提高模型对其他位置的注意力。之前的方法得到的z向量尽管以及包含了其他位置的编码信息，但是其仍主要受自身的影响。</p></li><li><p>Transformer有8个注意力头，即每个encoder/decoder有八组QKV</p></li><li><p>每组QKV分别按上述方法进行计算得到一组z向量，再将他们拼接起来叉乘一个新的矩阵$W^o$，得到一个新的z向量</p></li></ul><p><img src=https://jalammar.github.io/images/t/transformer_attention_heads_weight_matrix_o.png loading=lazy alt=transformer_attention_heads_weight_matrix_o></p><p><img src=https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png loading=lazy alt=transformer_multi-headed_self-attention-recap></p><h3 id=inside-the-multilayer-perception-多层感知器>Inside the Multilayer Perception 多层感知器</h3><p>推理需要事实作为依据，大模型是如何存储事实的？</p><p><img src=/p/transformer/155134.png width=1071 height=252 srcset="/p/transformer/155134_hu_8f6f785f2815ceaa.png 480w, /p/transformer/155134_hu_f7e93e0d0d392361.png 1024w" loading=lazy class=gallery-image data-flex-grow=425 data-flex-basis=1020px></p><h4 id=linear-up-projection>Linear (up projection)</h4><ul><li><p>乘一个矩阵$W_{\uparrow}$，将向量映射到高维空间</p></li><li><p>矩阵的每一行都是一个问题 (简化理解)</p></li><li><p>$\vec{B_{\uparrow}}$为Bias偏置，确保当embedding与问题相符时为1，其他情况为0或负</p></li></ul>$$
W_{\uparrow}\vec{E}+\vec{B_{\uparrow}}
$$<p><img src=/p/transformer/152128.png width=1167 height=597 srcset="/p/transformer/152128_hu_1cbb7e2b14c749ca.png 480w, /p/transformer/152128_hu_30313c75f06d0339.png 1024w" loading=lazy class=gallery-image data-flex-grow=195 data-flex-basis=469px></p><p><img src=/p/transformer/152234.png width=2401 height=702 srcset="/p/transformer/152234_hu_704987701938aa35.png 480w, /p/transformer/152234_hu_b0a456a5283fc5a.png 1024w" loading=lazy class=gallery-image data-flex-grow=342 data-flex-basis=820px></p><h4 id=relu线性整流函数>ReLU线性整流函数</h4><ul><li>对得到的高维向量进行处理：非线性函数，将负值映射为0，正值不变</li></ul><p><img src=/p/transformer/152726.png width=1016 height=640 srcset="/p/transformer/152726_hu_5bdb60ef4f1c6341.png 480w, /p/transformer/152726_hu_9f22fd598d1f9e65.png 1024w" loading=lazy class=gallery-image data-flex-grow=158 data-flex-basis=381px></p><h4 id=linear-down-projection>Linear (down projection)</h4><ul><li>对高维向量进行降维处理，使输出向量的维数降回到嵌入空间的维数</li></ul>$$
W_{\downarrow}(\space ReLU(W_{\uparrow}\vec{E}+B_{\uparrow})\space) + B_{\downarrow}
$$<p><img src=/p/transformer/153428.png width=2129 height=765 srcset="/p/transformer/153428_hu_eca90da885eb1c91.png 480w, /p/transformer/153428_hu_a1db886d0a38ac2b.png 1024w" loading=lazy class=gallery-image data-flex-grow=278 data-flex-basis=667px></p><h3 id=residuals-残差>Residuals 残差</h3><ul><li><p>在每个子层（如自注意力层和前馈神经网络层）中，残差连接允许输入信号绕过子层，直接与子层的输出相加。这意味着输出是子层的原始输入与子层的变换输出的和。</p></li><li><p>用于帮助解决深度神经网络训练过程中的梯度消失或梯度爆炸问题。</p><ul><li>梯度消失：梯度趋近于零，网络权重无法更新或更新的很微小，网络训练再久也不会有效果；</li><li>梯度爆炸：梯度呈指数级增长，变的非常大，然后导致网络权重的大幅更新，使网络变得不稳定。</li></ul>$$
output=x+F(x)\space(其中 F(x)F(x)F(x) 表示子层的复杂变换)
$$<p>即使 F(x)F(x)F(x) 部分可能会导致数值不稳定，恒等项 xxx 总能为梯度提供一个稳定的基础，从而改善整体训练的稳定性。</p></li></ul><p><img src=https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png loading=lazy alt=transformer_resideual_layer_norm_3></p><h2 id=decoder>Decoder</h2><ul><li>解码器也含有这两个层，但是中间增加了一个注意力层帮助解码器关注到相关的输入</li><li>解码器的self-attention与编码器稍有不同，其只关注输出序列中位于当前位置之前的token（masking掩码）<ul><li>掩码：在计算 $q_i\cdot k_j$ 时将将 $j>i$ 的项置为$-\infin$，在softmax的过程中$-\infin$会被转化为0，起到屏蔽作用</li></ul></li></ul><p><img src=/p/transformer/221542-1741617673211-3.png width=530 height=696 srcset="/p/transformer/221542-1741617673211-3_hu_420c5707aadfcde8.png 480w, /p/transformer/221542-1741617673211-3_hu_e0f8e7941159190f.png 1024w" loading=lazy class=gallery-image data-flex-grow=76 data-flex-basis=182px></p><p><img src=https://jalammar.github.io/images/t/transformer_decoding_2.gif loading=lazy alt=transformer_decoding_2></p><h2 id=linear-layer>Linear Layer</h2><p>实际上，decoder的输出是一个浮点型的向量，如何得到一个token？</p><ul><li>线性层是一个全链接神经网络，将decoder的输出向量转化为一个更大的向量（logits vector）</li><li>logits vector的维度等于“output vocabulary”所包含的token数（模型在训练中学习到的的token），logits vector中的每一格就是对某个token的评分</li><li>之后softmax layer会将logits vector转化为概率（归一化，所有数值相加等于一），选取概率最大的token</li></ul><p><img src=https://jalammar.github.io/images/t/transformer_decoder_output_softmax.png loading=lazy alt=transformer_decoder_output_softmax></p><h2 id=softmax-with-temperature>softmax with temperature</h2><p>softmax对向量进行归一化，确保$\sum x_n = 1$</p>$$
\begin{bmatrix}
x_1\\
x_2\\
x_3\\
...
\end{bmatrix}
\rightarrow
\begin{bmatrix}
\frac{e^{x_1/T}}{\sum_{n=0}^{N-1}e^{x_n/T}}\\
\frac{e^{x_2/T}}{\sum_{n=0}^{N-1}e^{x_n/T}}\\
\frac{e^{x_3/T}}{\sum_{n=0}^{N-1}e^{x_n/T}}\\
...
\end{bmatrix}
$$<ul><li>T越大，会给小数值赋予更多的权重，分布越均匀<ul><li>模型更愿意选择可能性较低的词</li></ul></li><li>T越小，较大的数组优势会更明显。<ul><li>T = 0时模型总是会选择最可能的词</li></ul></li></ul><h2 id=参考资料>参考资料</h2><ul><li>《Attention Is All You Need》 <a class=link href=https://arxiv.org/abs/1706.03762 target=_blank rel=noopener>https://arxiv.org/abs/1706.03762</a></li><li><a class=link href=https://jalammar.github.io/illustrated-transformer/ target=_blank rel=noopener>https://jalammar.github.io/illustrated-transformer/</a></li><li><a class=link href=https://www.3blue1brown.com/topics/neural-networks target=_blank rel=noopener>https://www.3blue1brown.com/topics/neural-networks</a></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/deep-learning/>Deep Learning</a>
<a href=/tags/transformer/>Transformer</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 Mar 10, 2025 15:32 UTC</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//lhy0424-disqus-com.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Az's Blog</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>